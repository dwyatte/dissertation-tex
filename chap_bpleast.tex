\documentclass[dwyatte_dissertation.tex]{subfiles} 
\begin{document}

\sloppy

\chapter{Effects of spatial and temporal prediction during prolonged learning of novel objects}
\label{chap:bpleast}

\section{Introduction}
TODO: Ref spatiotemporal invariance building -- and maybe balas's work

\section{Methods}

\subsection{Participants}
A total of 62 students from the University of Colorado Boulder participated in the experiment (ages 18-22, mean=19.11 years; 30 male, 32 female). All participants reported normal or corrected-to-normal vision and received course credit as	compensation for their participation. Informed consent was obtained from each participant prior to the experiment in accordance with Institutional Review Board policy at the University of Colorado.

\subsection{Stimuli}
Novel ``paper clip'' objects were used as stimuli (see Chapter \ref{chap:pleast} Methods). A total of eight objects were used -- four as targets and four as distractors. The four target objects were also used in the Chapter \ref{chap:pleast} experiment. Target and distractor objects were paired together for the purposes of the experiment. All objects are shown in Figure \ref{fig:bpleast_objs}.

% paperclip targets fig
\begin{figure}[h!]
\textbf{A} \\
\includegraphics[width=160mm]{figs/chap_bpleast/paperclip_targets.pdf} \\
\textbf{B} \\
\includegraphics[width=160mm]{figs/chap_bpleast/paperclip_distractors.pdf} \\
\caption{Novel ``paper clip'' objects}{Four target (\textbf{A}) and four distractor object pairs (\textbf{B}) used in the experiment. See Chapter \ref{chap:pleast} Methods for additional information.}
\label{fig:bpleast_objs}
\end{figure}

\subsection{Procedure}
The experiment was divided into 16 blocks, each containing a training period followed by a series of test trials (Figure \ref{fig:bpleast_task}). During the training period of a given block, participants observed one of the target objects rotate about its y-axis. The object either rotated coherently (i.e., spatially predictable, S+ conditions) or in a random manner (S- conditions). Coherent rotation was composed of adjacent views spaced 12 degrees apart. The object made four complete rotations during the study period. All views of the object were still presented four times each in the random case. The presentation rate during the study period was either 10 Hz with a 50 ms on time and 50 ms off time (i.e., temporally predictable, T+ conditions) or variable with a 50 ms on time and off times ranging from 16.67-400 ms (T- conditions). 

The S+/- and T+/- conditions were crossed and each of the target-distractor object pairs was assigned to one of the four conditions. These assignments were approximately counterbalanced across participants (Assignment 1: \textit{N}=15; Assignment 2: \textit{N}=17; Assignment 3: \textit{N}=15; Assignment 4: \textit{N}=15). Each block condition with its target-distractor pairing was repeated for four blocks during the experiment. Block order randomized was randomized for each participant.

During each block, participants were instructed to study the target object during the training period and then complete a series of 30 test trials. On each test trial, either the target object or its paired distractor was presented. Participants were instructed to respond ``same'' if they believed the object depicted the trained target object or ``different'' if they believed it depicted the distractor object. Half of the test trials contained 15 views of the target object spaced 24 degrees apart, and the other half contained 15 views of the distractor, also spaced 24 degrees apart. Test trials were shown in a random order and feedback was withheld to prevent participants from changing their response criteria over the course of a block. 

The experiment was displayed on an LCD monitor at native resolution operating at 60 Hz using the Psychophysics Toolbox Version 3 \cite{Brainard97,Pelli97}. All stimuli were presented at central fixation on an isoluminant 50\% gray background and subtended approximately 5 degrees of visual angle. Test trials began with a fixation cross (200 ms) followed by a blank (400 ms) followed by the probe stimulus (100 ms). Participants were required to respond within 2000 ms. Subsquent test trials were separated by a variable intertrial interval of 1000-1400 ms.

The experiment began with a practice block to ensure that participants understood the task. The training period during the practice block was always spatially and temporally predictable and used a reserved target object and distractor that were not further used in any of the experimental blocks. During the practice test trials, participants received feedback after responding according to whether they were correct or incorrect. After completing the practice block, participants were informed that future training periods could be presented in spatially and/or temporally unpredictable manners.

% paperclip targets fig
\begin{figure}[h!]
\includegraphics[width=160mm]{figs/chap_bpleast/paperclip_task.pdf} \\
\caption{Experimental procedure}{Experimental trials were composed of a training period followed by a testing period. The training period depicted a target object rotating a total of four times around its vertical axis. Rotation was either spatially and temporally predictable, spatially predictable or temporally predictable only, or completely unpredictable. The test period contained 30 trials that depicted either the training object or its paired distractor at 15 viewing angles each.}
\label{fig:bpleast_task}
\end{figure}

\section{Results}
% timeouts removed from data
Three subjects were excluded from behavioral analysis for accuracy 2.7$\sigma$ (or further) below mean accuracy across subjects. All three excluded subjects were assigned condition-object 3 resulting in the final counterbalancing -- Assignment 1: \textit{N}=15; Assignment 2: \textit{N}=14; Assignment 3: \textit{N}=15; Assignment 4: \textit{N}=15. The remaining 59 subjects were submitted to a 2x2 ANOVA with spatial and temporal predictability as within-subjects factors and counterbalancing assignment as a between-subjects factor. Accuracy and reaction times were collected during the experiment and were used to compute \textit{d'}, a measure of sensitivity that takes into account response bias, and inverse efficiency, a measure that combines accuracy and reaction times \cite{TownshendAshby78,TownshendAshby83}. These behavioral measures are plotted in Figure \ref{fig:bpleast_behave}.

% oh, behave
\begin{figure}[h!]
\begin{center}
\begin{tabular}{ll}
\includegraphics[width=80mm]{figs/chap_bpleast/results_accuracy.pdf} & 
\includegraphics[width=80mm]{figs/chap_bpleast/results_dprime.pdf} \\
\includegraphics[width=80mm]{figs/chap_bpleast/results_rt.pdf} &
\includegraphics[width=80mm]{figs/chap_bpleast/results_ie.pdf} \\
\end{tabular}
\end{center}
\caption{Behavioral measures of spatial and temporal predictability}{Accuracy, \textit{d'} (sensitivity), reaction time, and inverse efficiency (reaction time divided by percent correct) as a function of predictability during the training period. S-/+ refers to spatially unpredictable and predictable, T-/+ to temporally unpredictable and predictable. Error bars depict within-subjects error using the method described in \protect\incite{Cousineau05} adapted for standard error.}
\label{fig:bpleast_behave}
\end{figure}

% Acc
% Assignment: F(1, 57) = 0.156, p = 0.694
% Spatial: F(1, 57) = 4.496, p = 0.0383 * 
% Temporal: F(1, 57) = 4.149, p = 0.0463 * 
% Int: F(1, 57) = 0.197, p = 0.659

Overall, subjects were less accurate when the training period was spatially predictable (\textit{F}(1, 57) = 4.50, \textit{p} = 0.038) or temporally predictable (\textit{F}(1, 57) = 4.20, \textit{p} = 0.046). The interaction between spatial and temporal predicability failed to reach significance (\textit{F}(1, 57) = 0.20, \textit{p} = 0.659). Subjects were least accurate for the combined spatial and temporal predictability condition (denoted S+T+ in Figure \ref{fig:bpleast_behave}). This condition significantly differed from the completely unpredictable condition (S-T-) (\textit{t}(58) = -2.8587, \textit{p} = 0.001), and trended toward significance for conditions with only spatial or only temporal predictability (S+T+ versus S+T-, \textit{t}(58) = -1.60, \textit{p} = 0.116; S-T- versus S+T+ versus S-T+, \textit{t}(58) = -1.77, \textit{p} = 0.082).

% d'
% Assignment: F(1, 57) = 0.762, p = 0.386
% Spatial: F(1, 57) = 3.066, p = 0.0853 .
% Temporal: F(1, 57) =  3.00, p = 0.0887 .
% Int: F(1, 57) = 0.00, p = 0.985  

When responses are transformed into \textit{d'}, effects of spatial predictability and temporal predictability during the training period trended toward significance (spatial, \textit{F}(1, 57) = 3.07, \textit{p} = 0.085; temporal, \textit{F}(1, 57) = 3.00, \textit{p} = 0.089). The interaction between spatial and temporal predicability failed to reach significance (\textit{F}(1, 57) = 0.00, \textit{p} = 0.985). The pattern of results as a function of predictability during the training period was the same as for accuracy, and thus this failure to reach critical significance likely reflects the loss of power when transforming responses into \textit{d'} due to discarding misses and correct rejections. 

% RT
% Assignment: F(1, 57) = 0.713, p = 0.402
% Spatial: F(1, 57) = 10.99, p = 0.00159 *
% Temporal: F(1, 57) = 0.527, p = 0.471
% Int: F(1, 57) = 1.209, p = 0.2761 

% IE
% Assignment: F(1, 57) = 0.91, p = 0.344
% Spatial: F(1, 57) = 9.640, p = 0.00296 *
% Temporal: F(1, 57) = 0.445, p = 0.507
% Int: F(1, 57) = 0.71 , p = 0.403   

Subjects were slower to respond when the training period was spatially predictable (\textit{F}(1, 57) = 10.99, \textit{p} = 0.002). A similar effect for temporal predictability failed to reach significance (\textit{F}(1, 57) = 0.53, \textit{p} = 0.471), nor did the interaction between spatial and temporal predictability (\textit{F}(1, 57) = 1.21, \textit{p} = 0.276). Effects on inverse efficiency (defined as reaction time divided by percent correct) were similar. Inverse efficiency was highest when the training period was spatially predictable (\textit{F}(1, 57) = 9.64, \textit{p} = 0.003), but did not significantly differ as a function of temporal predictability (\textit{F}(1, 57) = 0.45, \textit{p} = 0.507), nor when considering the interaction between spatial and temporal predictability (\textit{F}(1, 57) = 0.71, \textit{p} = 0.403).

Effects were highly variable across target objects (Figure \ref{fig:bpleast_behave_obj}). Target-condition assignment did not significantly affect any of the behavioral measures (all \textit{p}'s $>$ 0.05), but often interacted with predictability effects and their interactions. One reason for this variability regards the orthographic projection used to render the objects. Previous research has indicated that recognition accuracy fluctuates as a function of how well the two-dimensional projection of an object captures its full three-dimensional structure \cite{BalasSinha09b}. For example, when there is a large amount of foreshortening in the projection, it could be difficult to infer the length of line segments that compose the object, impairing recognition. These degenerate projections are generally diametrically opposed on the object. 

% oh, behave, pt 2: objs
\begin{figure}[h!]
\begin{center}
\begin{tabular}{ll}
\includegraphics[width=80mm]{figs/chap_bpleast/results_accuracy_obj.pdf} &
\includegraphics[width=80mm]{figs/chap_bpleast/results_dprime_obj.pdf} \\
\includegraphics[width=80mm]{figs/chap_bpleast/results_rt_obj.pdf} &
\includegraphics[width=80mm]{figs/chap_bpleast/results_ie_obj.pdf} \\
\end{tabular}
\end{center}
\caption{Behavioral measures for each target object}{Accuracy, \textit{d'}, reaction time, and inverse efficiency for each target object. Horizontal axes denote target and colors predictability during the training period. Error bars depict between-subjects standard error.}
\label{fig:bpleast_behave_obj}
\end{figure}

To investigate this hypothesis, accuracy was computed as a function of viewing angle for each target object to investigate whether it interacted with predictability during the training period (Figure \ref{fig:bpleast_behave_rot}). Only accuracy was considered in this analysis as each data point only corresponded to four trials per subject and thus transformation to \textit{d'} was not plausible. Test trials during which distractor objects were presented were also excluded from this analysis since there is no consistent relationship between the targets and distractors across viewing angles and thus they would only contribute noise. With the exception of target object 1, all objects indicated fluctuations in accuracy as a function of viewing angle with two diametrically opposed degenerate views. The most consistent differences in accuracy between training conditions appeared to be localized to the troughs of the accuracy function, corresponding to these degenerate views.

% oh, behave, pt 3: rots
\begin{figure}[h!]
\begin{center}
\begin{tabular}{ll}
\includegraphics[width=80mm]{figs/chap_bpleast/results_accuracy_rot_obj1.pdf} &
\includegraphics[width=80mm]{figs/chap_bpleast/results_accuracy_rot_obj2.pdf} \\
\includegraphics[width=80mm]{figs/chap_bpleast/results_accuracy_rot_obj3.pdf} &
\includegraphics[width=80mm]{figs/chap_bpleast/results_accuracy_rot_obj4_montage.pdf} \\
\end{tabular}
\end{center}
\caption{Accuracy as a function of viewing angle for each target object}{Target accuracy at each viewing angle presented during the test periods. Horizontal axes denote viewing angle and colors predictability during the training period. Error bars depict between-subjects standard error. Diametrically opposed foreshortened views and one canonical view are shown for target object 4.}
\label{fig:bpleast_behave_rot}
\end{figure}

Standard statistical tests did not have enough power to detect differences between conditions for degenerate views due to the low trial counts for each data point. To address this design limitation, a bootstrapping method was used to resample the available data in these cases. The accuracy function over viewing angles was collapsed across conditions and the two minima associated with degenerate views were identified for each object. For target object 1, this corresponded to angles $\theta$ = \{24$^\circ$, 312$^\circ$\}, object 2: $\theta$ = \{48$^\circ$, 240$^\circ$\} object 3: $\theta$ = \{144$^\circ$, 312$^\circ$\}, and object 4 $\theta$ = \{24$^\circ$, 192$^\circ$\}. Accuracy for the completely unpredictable (S-T-) and combined spatial and temporal predictability (S+T+) conditions during training was averaged at these viewing angles and resampled with replacement from the 59 subjects for 10000 iterations. This produced distributions for degenerate view accuracy for each object (Figure \ref{fig:bpleast_behave_bootstrap}). Accuracy for was lower for degenerate views for the combined spatial and temporal predictability condition for all target objects except target 1, which didn't exhibit the patterned accuracy function that other targets did. The S+T+/S-T- difference in accuracy for degenerate views was significant at the 90\% alpha level (i.e., the confidence interval of the difference between means did not include zero) for all target objects except target 1.

% oh, behave, pt 4: bootstraps
\begin{figure}[h!]
\begin{center}
\begin{tabular}{ll}
\includegraphics[width=160mm]{figs/chap_bpleast/results_bootstrap_montage.pdf}
\end{tabular}
\end{center}
\caption{Bootstrapped accuracy for degenerate views}{Average target accuracy for degenerate views resampled with replacement from the 59 subjects for 10000 iterations. Viewing angle for averaging is noted for each target object. Asterisks denote significant differences based on 90\% confidence intervals.}
\label{fig:bpleast_behave_bootstrap}
\end{figure}

\section{Discussion}\subsection{Summary of results}
The work described in this chapter investigated how predictability biased learned representations of novel objects. The experimental paradigm used to address this question involved training participants to recognize novel objects while manipulating their spatial and temporal predictability. Somewhat surprisingly, accuracy was lowest when stimuli were learned in a combined spatially and temporally predictable context and highest when learned in a completely unpredictable context. Reaction times were also slower when objects were learned with spatial predictability.

Behavioral measures were highly variable across objects. There was some indication that differences between predictability conditions during training were driven primarily by degenerate viewing angles caused by three-dimensional foreshortening in the objects used. A foreshortening model has previously accounted for the principal component of variability in recognition accuracy for the same ``paper clip'' objects used here \cite{BalasSinha09b}, but only in a combined spatial and temporal predictability learning context.

\subsection{A behavioral disadvantage for spatial prediction during object learning}

Based on previous research, it is unclear whether spatial predictability is used by the brain during object learning and whether it is actually advantageous. Initial investigations described in \incite{LawsonHumphreysWatson94} identified the expected increase in recognition accuracy for spatially predictable sequences. The foreshortening model advanced in \cite{BalasSinha09b} was also improved by incorporating spatial information (e.g., the first- and second-order derivatives of the foreshortening function over object views). Furthermore, a number of computational models, including LeabraTI (Chapter \ref{chap:leabrati}), use learning rules that incorporate associations between subsequent inputs to learn object representations \cite{Foldiak91,StringerPerryRollsEtAl06,WallisBaddeley97,IsikLeiboPoggio12}.

Experiments described in \incite{HarmanHumphrey99} failed to find any positive or negative effects of spatial predictability on accuracy. They did, however, increase in reaction time for objects learned in a spatially predictable context, similar to the one reported here. One possible reason for the slowing of reaction times for objects learned with spatial predictability is that less attention is necessary in these conditions. A constantly changing sequence of views might require more attentive processing to encode whereas the relatively low amount of change between views in spatially predictable sequences is less ``surprising'' and some views might be overlooked during encoding. However, there was some indication that the adverse effect of spatial predictability was driven primarily by the degenerate views of the stimuli used in the present work. A more focused experiment would be necessary to explicitly test the hypothesis impaired for degenerate views learned in a spatially predictable context and relatively intact for canonical views, but the interpretation of this hypothesis if confirmed is still discussed here. % to motivate simulations described in other chapters and future work.

% * degraaf -- lower hit rate for 10 Hz

\subsection{Spatiotemporal prediction biases development of invariance}
The theory advanced here is that spatially predictable sequences promote the development of invariance over the sequence transformation given prolonged learning. For example, if a three-dimensional object rotates in depth in a spatially predictable manner, associations can be formed between subsequent views using a temporal association rule. Integrating over small changes in viewing angle is easier than large changes \cite{LogothetisPaulsBulthoffEtAl94,LogothetisPaulsPoggio95} and thus, the problem of constructing invariance can be solved gradually instead of all at once. A large body of previous work supports this idea. 

Behavioral experiments by Wallis, Bulthoff, and colleagues have used a predictability paradigm for studying face recognition similar to the one used in the present work, but in which spatially unpredictable sequences are characterized by swapping the identity of faces mid-sequence. Most observers were unaware of these identity swaps, but they significantly impaired the discriminability of swapped identities compared to stable identities \cite{WallisBulthoff01}. The effects were originally reported for identities swapped during depth-rotated sequences but have since been extended to swaps during changes in orientation and illumination \cite{WallisBackusLangerEtAl09}. Together, these results suggest that associations are made between subsequent members of a sequence to construct invariance to transformations.

Single unit recordings from Li and DiCarlo using a similar swap paradigm have shown exactly how this invariance is constructed. 

\incite{LiDiCarlo08}
\incite{LiDiCarlo10}
\incite{LiDiCarlo12}

% and what about temporal?
% doesn't even have to be conscious prediction -- provided automatically by T+

% neurons!
% * MeyerOlson11 
% * Not about invariance per se -- SakaiMiyashita91,MeyerOlson11 -- but related to why static views might not be enough
% Li & Dicarlo spatiotemporal learning -- but for size and position
% * LiDiCarlo08,LiDiCarlo10

% \incite{WallisBulthoff99} (review) -- loss of canonicality
%One important aspect of view-dependent recognition is that it is most noticeable for unfamiliar objects, or for objects usually seen from a particular viewpoint23 – for which the familiar view is referred to as ‘canonical’. For other familiar objects it has long been known that recognition is view- invariant24,26. This is, however, still consistent with a view- based model if one assumes that for familiar objects, enough views are stored to remove any view-specific effects. To demonstrate that view-dependence is purely a function of familiarity, Edelman and Bülthoff investigated the effects of extensive training, and showed that it can indeed counter initial view specificity27 (Fig. 5).

% * Perret et al -- view dependent cells faster to respond than view invariance cells

\bibliographystyle{apa}
\bibliography{ccnlab}
\end{document}